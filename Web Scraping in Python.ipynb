{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c08fb4d",
   "metadata": {},
   "source": [
    "\n",
    "## WEB SCRAPING IN PYTHON: WIKIPEDIA TABLE\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this guide, we will scrape table data from the Wikipedia page titled **\"The 30 largest countries by net national wealth (in billions USD)\"**. You can find the page [here](https://en.wikipedia.org/wiki/List_of_countries_by_total_wealth).\n",
    "\n",
    "This process involves:\n",
    "1. Fetching the webpage.\n",
    "2. Parsing the HTML content.\n",
    "3. Extracting data into a structured format using Python libraries.\n",
    "\n",
    "### Required Libraries\n",
    "\n",
    "To perform web scraping and handle data, we will use the following Python libraries:\n",
    "- `requests` for fetching web pages.\n",
    "- `beautifulsoup4` for parsing HTML content.\n",
    "- `pandas` for data manipulation and saving data to CSV.\n",
    "\n",
    "Before running the code, make sure to install the necessary libraries. In a Jupyter Notebook cell, you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aaae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install beautifulsoup4\n",
    "# !pip install pandas \n",
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4127519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e8d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the Webpage\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_total_wealth'\n",
    "page = requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20227572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML Content\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "print(soup.prettify())  # Pretty-print the HTML content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4abbb5",
   "metadata": {},
   "source": [
    "### Inspect the Wikipedia Page \n",
    "To locate the table we need:\n",
    "Right-click on the webpage and select \"Inspect\" to open the developer tools.\n",
    "There are multiple tables on the page, and we need the second one. **\"The 30 largest countries by net national wealth (in billions USD)\"** [List_of_countries_by_total_wealth](https://en.wikipedia.org/wiki/List_of_countries_by_total_wealth) \n",
    "\n",
    "Identify the Target Table\n",
    "The 1st, 3rd, and 4th tables have the class **wikitable sortable jquery-tablesorter.**\n",
    "The 2nd table has the class **wikitable static-row-numbers.**. \n",
    "\n",
    "ðŸ”—[Inspect page](https://github.com/DataVizStory/Web-Scraping/blob/main/Images/Wiki_table.gif)\n",
    "\n",
    "Two ways target the 2nd table: \n",
    "+ via tag\n",
    "+ via class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138aa04",
   "metadata": {},
   "source": [
    "### Via tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368ac766",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('table')  # Find all tables on the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf75ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This returns a list of all tables. We can access the second table using index 1:\n",
    "soup.find_all('table')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e013579",
   "metadata": {},
   "source": [
    "### Via class "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0555eb1f",
   "metadata": {},
   "source": [
    "Alternatively, use the unique class name (**'wikitable static-row-numbers'**) for the second table: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb4c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('table', class_=\"wikitable static-row-numbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, we'll use the first way to find table via tag :\n",
    "table = soup.find_all('table')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c853e80",
   "metadata": {},
   "source": [
    "### Extract Column Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the table headers: \n",
    "all_table_titles=table.find_all('th')\n",
    "all_table_titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dba0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_titles = [title.text.strip() for title in all_table_titles]\n",
    "print(table_titles)  # Output the cleaned table titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880115c8",
   "metadata": {},
   "source": [
    "### Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab114958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create datatable:\n",
    "df = pd.DataFrame(columns=table_titles)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7053e66",
   "metadata": {},
   "source": [
    "### Extract and Populate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract table rows and populate the DataFrame:\n",
    "column_data = table.find_all('tr')\n",
    "\n",
    "for row in column_data[1:]:  # Skip the header row\n",
    "    row_data = row.find_all('td')\n",
    "    individual_row_data = [data.text.strip() for data in row_data]\n",
    "    df.loc[len(df)] = individual_row_data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89677881",
   "metadata": {},
   "source": [
    "## Alternative Method to Fetch Table Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b62b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fetch the page and read the table directly into a DataFrame\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_total_wealth'\n",
    "dfs = pd.read_html(url)\n",
    "\n",
    "# The desired table is the second one (index 1)\n",
    "df2 = dfs[1]\n",
    "\n",
    "# Display the DataFrame\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e4bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your DataFrame to a CSV file\n",
    "df.to_csv('Companies.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
